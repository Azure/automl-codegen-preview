# ---------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# ---------------------------------------------------------
# This file has been autogenerated by the Azure Automated Machine Learning SDK.


import numpy
import pickle
import dill
import joblib

def get_training_dataset():
    from azureml.core import Dataset, Workspace, Run
    
    ws = Run.get_context().experiment.workspace
    dataset = Dataset.get_by_id(workspace=ws, id='dataset_id')
    return dataset.to_pandas_dataframe()


def prepare_data(dataframe):
    from azureml.automl.runtime import data_cleaning
    
    label_column_name = 'demand'
    
    # extract the features, target and sample weight arrays
    y_train = dataframe[label_column_name].values
    X_train = dataframe.drop([label_column_name], axis=1)
    sample_weights = None
    X_train, y_train, sample_weights = data_cleaning._remove_nan_rows_in_X_y(X_train, y_train, sample_weights, is_timeseries=True, target_column=label_column_name)
    return X_train, y_train, sample_weights


def generate_data_transformation_config():
    from azureml.automl.core.featurization.featurizationconfig import FeaturizationConfig
    from azureml.automl.runtime.featurizer.transformer.timeseries.category_binarizer import CategoryBinarizer
    from azureml.automl.runtime.featurizer.transformer.timeseries.missingdummies_transformer import MissingDummiesTransformer
    from azureml.automl.runtime.featurizer.transformer.timeseries.numericalize_transformer import NumericalizeTransformer
    from azureml.automl.runtime.featurizer.transformer.timeseries.restore_dtypes_transformer import RestoreDtypesTransformer
    from azureml.automl.runtime.featurizer.transformer.timeseries.short_grain_dropper import ShortGrainDropper
    from azureml.automl.runtime.featurizer.transformer.timeseries.time_index_featurizer import TimeIndexFeaturizer
    from azureml.automl.runtime.featurizer.transformer.timeseries.time_series_imputer import TimeSeriesImputer
    from azureml.automl.runtime.featurizer.transformer.timeseries.timeseries_transformer import TimeSeriesPipelineType
    from azureml.automl.runtime.featurizer.transformer.timeseries.timeseries_transformer import TimeSeriesTransformer
    from builtins import str
    from collections import OrderedDict
    from numpy import dtype
    from numpy import nan
    from sklearn.pipeline import Pipeline
    
    transformer_list = []
    transformer1 = MissingDummiesTransformer(
        numerical_columns=['precip', 'temp']
    )
    transformer_list.append(('make_numeric_na_dummies', transformer1))
    
    transformer2 = TimeSeriesImputer(
        end=None,
        freq='H',
        impute_by_horizon=False,
        input_column=['precip', 'temp'],
        limit=None,
        limit_direction='forward',
        method=OrderedDict([('ffill', [])]),
        option='fillna',
        order=None,
        origin=None,
        value={'precip': 0.0, 'temp': 56.19}
    )
    transformer_list.append(('impute_na_numeric_datetime', transformer2))
    
    transformer3 = ShortGrainDropper()
    transformer_list.append(('grain_dropper', transformer3))
    
    transformer4 = RestoreDtypesTransformer(
        target_column='_automl_target_col',
        dtypes={'precip': dtype('float64'), '_automl_target_col': dtype('float64'), 'temp': dtype('float64')}
    )
    transformer_list.append(('restore_dtypes_transform', transformer4))
    
    transformer5 = NumericalizeTransformer(
        include_columns=set(),
        exclude_columns=set(),
        categories_by_col={}
    )
    transformer_list.append(('make_categoricals_numeric', transformer5))
    
    transformer6 = TimeIndexFeaturizer(
        correlation_cutoff=0.99,
        country_or_region=None,
        datetime_columns=None,
        force_feature_list=None,
        freq='H',
        overwrite_columns=True,
        prune_features=True
    )
    transformer_list.append(('make_time_index_featuers', transformer6))
    
    transformer7 = CategoryBinarizer(
        columns=[],
        drop_first=False,
        dummy_na=False,
        encode_all_categoricals=False,
        prefix=None,
        prefix_sep='_'
    )
    transformer_list.append(('make_categoricals_onehot', transformer7))
    
    pipeline = Pipeline(steps=transformer_list)
    tst = TimeSeriesTransformer(
        pipeline=pipeline,
        pipeline_type=TimeSeriesPipelineType.FULL,
        max_horizon=48,
        use_stl=None,
        seasonality=24,
        force_time_index_features=None,
        grain_column_names=['_automl_dummy_grain_col'],
        drop_column_names=[],
        origin_time_colname='origin',
        group=None,
        country_or_region=None,
        freq='H',
        time_column_name='timeStamp',
        featurization_config=FeaturizationConfig(
            blocked_transformers=None,
            column_purposes=None,
            transformer_params=None,
            dataset_language=None,
            drop_columns=None,
            prediction_transform_type=None
        ),
        time_index_non_holiday_features=['_automl_year', '_automl_half', '_automl_quarter', '_automl_month', '_automl_day', '_automl_hour', '_automl_am_pm', '_automl_hour12', '_automl_wday', '_automl_qday', '_automl_week'],
        lookback_features_removed=False
    )
    
    return tst


def generate_algorithm_config():
    from azureml.automl.runtime.shared._exponential_smoothing import ExponentialSmoothing
    from numpy import array
    
    algorithm = ExponentialSmoothing(
        timeseries_param_dict={'time_column_name': 'timeStamp', 'grain_column_names': None, 'drop_column_names': [], 'overwrite_columns': True, 'dropna': False, 'transform_dictionary': {'min': '_automl_target_col', 'max': '_automl_target_col', 'mean': '_automl_target_col'}, 'max_horizon': 48, 'origin_time_colname': 'origin', 'country_or_region': None, 'n_cross_validations': 3, 'short_series_handling': True, 'max_cores_per_iteration': 1, 'feature_lags': None, 'target_aggregation_function': None, 'seasonality': 24, 'use_stl': None, 'freq': 'H', 'short_series_handling_configuration': 'auto', 'target_lags': [0], 'target_rolling_window_size': 0, 'arimax_raw_columns': ['precip', 'timeStamp', 'temp']}
    )
    
    return algorithm


def build_model_pipeline():
    from sklearn.pipeline import Pipeline
    from azureml.automl.runtime.shared.model_wrappers import ForecastingPipelineWrapper
    
    pipeline = Pipeline(
        steps=[('tst', generate_data_transformation_config()),
               ('model', generate_algorithm_config())]
    )
    forecast_pipeline_wrapper = ForecastingPipelineWrapper(pipeline, stddev=[515.970279075003])
    
    return forecast_pipeline_wrapper


def train_model(X, y, sample_weights):
    model_pipeline = build_model_pipeline()
    
    model = model_pipeline.fit(X, y)
    return model


def main():
    # The following code is for when running this code as part of an AzureML script run.
    from azureml.core import Run
    run = Run.get_context()
    
    df = get_training_dataset()
    X, y, sample_weights = prepare_data(df)
    model = train_model(X, y, sample_weights)
    
    y_pred = model.predict(X)
    
    # NOTE: You may need to use joblib.load() to load the model if pickle.load() does not work.
    joblib.dump(model, 'model.pkl')
    run.upload_file('outputs/model.pkl', 'model.pkl')


if __name__ == '__main__':
    main()